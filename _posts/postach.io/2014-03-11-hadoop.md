---
layout: post
title: "如何确定Hadoop守护进程分别会在哪台机器上运行"
description: ""
category: "Hadoop"
---
{% include JB/setup %}


经过一段时间的配置，Hadoop环境总算运行起来了，但是，为何主节点就没有跑tasktracker和datanode进程，slave节点也没有跑secondary进程，Hadoop是如何控制的呢？

<!-- more -->


经过看权威指南（267页）和跟群里同学讨论，还有自己测试，最终确定：

  


> tasktracker和datanode这两个守护进程 —— 只会在conf/slaves文件里指定的那些节点上运行

> secondarynamenode 这个守护进程 —— 只会在conf/masters文件里指定的那个节点上运行

> namenode和jobtracker这两个守护进程 —— 他们只会在同一台server上运行，可以通过core-site.xml和mapred-site.xml来确定要运行的主机。并且，假如说配置文件里指定的是node1，那么必须要在node1这台server上运行start脚本。否则，tasktracker，datanode和secondarynamenode这些进程都能顺利启动，而namenode和jobtracker无法启动。

  


  


实际测试结果：

  


**我的配置环境**：（请对下面频繁出现的delly表示淡定和理解。。。因为我的英文名叫Delly。。。）

  


dellypc-master，dellypc-1，dellypc-2三台主机。

  


其中，masters文件里记录了dellypc-master（表示secondarynamenode在dellypc-master上运行），slaves文件里记录了dellypc-1和dellypc-2（表示datanode和tasktracker要在dellypc-1和dellypc-2上运行）。

core-site.xml文件里：hdfs://dellypc-master:9000， mapred-site.xml文件里：<value>dellypc-master:9001</value>。（表示namenode跟jobtracker都在dellypc-master上运行，分别监听9000和9001端口）

  


#### 正常情况：

  


在dellypc-master上执行start-all.sh脚本，完全正常。

结果：

dellypc-master：namenode，jobtracker和secondarynamenode

dellypc-1：tasktracker和datanode

dellypc-2：tasktracker和datanode

  


#### 测试1：

  


在dellypc-1上执行start-all.sh脚本，namenode和jobtracker没有启动，其他进程正常启动。

结果：

dellypc-master：secondarynamenode

dellypc-1：tasktracker和datanode

dellypc-2：tasktracker和datanode

  


  


#### 测试2：

  


修改core-site.xml： <value>hdfs://dellypc-1:9000</value>

修改mapred-site.xml： <value>dellypc-1:9001</value>

然后，再dellypc-1上执行start-all.sh，

结果：

dellypc-master：secondarynamenode

dellypc-1：tasktracker，datanode和jobtracker

dellypc-2：tasktracker和datanode

  


奇怪的是namenode没有启动起来！按照预期，namenode应该会在dellypc-1上启动的嘛。。。为什么？

  


纠结了一会儿，大概想出来问题的关键了：因为在dellypc-1上没有格式化的hdfs文件系统，所以无法正常启动namenode。

  


也许你会跟我一样想说格式化一下试试呗，于是我就做了。。。但是格式化的时候失败了，因为我在hdfs-site.xml这个文件里设置了两个namenode元数据存储的目录，但是dellypc-1上没有其中的一个目录。于是我想就改回去吧。配置改回去，结果发现，datanode启动不了了。。。。。所以说啊，这个hdfs应该是一种分布式系统，跟所有的节点可能都会有关联。。。

  


  


最后又把dellypc-1和dellypc-2上的hadoop文件夹删掉，又重新从主节点拷贝了一份，这才恢复了正常。

  


  


这些试验，足够解决我的疑问了。希望也同样能帮到有同样疑问的同学。
